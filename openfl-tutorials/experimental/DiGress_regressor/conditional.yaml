# @package _global_
general:
    name : 'try_checkpoint'
    gpus : 1
    wandb: 'disabled'
    sample_every_val: 5
    samples_to_generate: 10
    samples_to_save: 5
    chains_to_save: 1
    test_only: False
    check_val_every_n_epochs: 5

    # General settings
    guidance_target: 'both'
    #guidance_target: null       # null is the default when not using guidance. Otherwise, use 'homo', 'mu' or 'both'
    resume: null            # If resume, path to ckpt file from outputs directory in main directory
    log_every_steps: 50
    number_chain_steps: 50        # Number of frames in each gif

    final_model_samples_to_generate: 10000
    final_model_samples_to_save: 30
    final_model_chains_to_save: 20

    evaluate_all_checkpoints: False

train:
    ema_decay : 0
    batch_size: 512
    save_model: True
    n_epochs : 500
    lr: 0.0002
    clip_grad: null          # float, null to disable
    num_workers: 0
    progress_bar: false
    weight_decay: 1e-12
    optimizer: adamw # adamw,nadamw,nadam => nadamw for large batches, see http://arxiv.org/abs/2102.06356 for the use of nesterov momentum with large batches
    amsgrad: true
    overfit: false
    seed: 0

model:
    n_layers: 5
    extra_features: null

    # Model settings
    type: 'discrete'
    transition: 'marginal'                          # uniform or marginal
    model: 'graph_tf'
    diffusion_steps: 500
    diffusion_noise_schedule: 'cosine'              # 'cosine', 'polynomial_2'

    # Do not set hidden_mlp_E, dim_ffE too high, computing large tensors on the edges is costly
    # At the moment (03/08), y contains quite little information
    hidden_mlp_dims: {'X': 256, 'E': 128, 'y': 128}

    # The dimensions should satisfy dx % n_head == 0
    hidden_dims : {'dx': 256, 'de': 64, 'dy': 64, 'n_head': 8, 'dim_ffX': 256, 'dim_ffE': 128, 'dim_ffy': 128}

    lambda_train: [5, 0]

dataset:
    name: 'qm9'            # qm9, qm9_positional
    datadir: 'data/qm9/qm9_pyg/'
    remove_h: True
    random_subset: null
    pin_memory: False

